# -*- coding: utf-8 -*-
"""Image Recognition (AlexNet).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PDyMhEcBvFxCnBwG-yC0iOvOt19sK69G
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d

!unzip fruit-and-vegetable-image-recognition.zip

train_dir='/content/train'
test_dir='/content/test'
val_dir='/content/validation'

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import accuracy_score
from PIL import Image
import numpy as np

BATCH_SIZE=64
EPOCHS=20

train_transform=torchvision.transforms.Compose([
    torchvision.transforms.Resize((227,227)),
    torchvision.transforms.RandomCrop((227,227)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
])

test_transform=torchvision.transforms.Compose([
    torchvision.transforms.Resize((227,227)),
    torchvision.transforms.CenterCrop((227,227)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
])

train_dataset=torchvision.datasets.ImageFolder(train_dir,transform=train_transform)
test_dataset=torchvision.datasets.ImageFolder(test_dir,transform=test_transform)
val_dataset=torchvision.datasets.ImageFolder(val_dir,transform=test_transform)

train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)
test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)
val_loader=torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False)

for image,label in train_loader:
  print(image.shape)
  print(label)
  break

class Alexnet(torch.nn.Module):
  def __init__(self,num_classes):
    super().__init__()
    self.features=nn.Sequential(
    nn.Conv2d(3,96,kernel_size=11,stride=4,padding=2,bias=False),
    nn.ReLU(inplace=True),
    nn.MaxPool2d(kernel_size=3,stride=2,padding=0),
    nn.Conv2d(96,192,kernel_size=5 ,stride=1,padding=2,bias=False),
    nn.ReLU(inplace=True),
    nn.MaxPool2d(kernel_size=3,stride=2,padding=0),
    nn.Conv2d(192,384,kernel_size=3,stride=1,padding=1,bias=False),
    nn.ReLU(inplace=True),
    nn.Conv2d(384,256,kernel_size=3,stride=1,padding=1,bias=False),
    nn.ReLU(inplace=True),
    nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1,bias=False),
    nn.ReLU(inplace=True),
    nn.MaxPool2d(kernel_size=3,stride=2,padding=0))

    self.classifier=nn.Sequential(
    nn.Dropout(p=0.5),
    nn.Linear(256 * 6 * 6, 4096),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5),
    nn.Linear(4096,4096),
    nn.ReLU(inplace=True),
    nn.Linear(4096,num_classes)
    )

  def forward(self,x):
    x=self.features(x)
    x=x.view(x.size(0),256*6*6)
    x=self.classifier(x)
    return x

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model=Alexnet(36).to(device)

optimizer=optim.Adam(model.parameters(),lr=0.001)

criterion=nn.CrossEntropyLoss()

def accuracy(outputs,labels):
  _,predicted= torch.max(outputs,1)
  correct= (predicted == labels).sum().item()
  total= labels.size(0)

  return correct/total

def compute_accuracy(model,data_loader):
  model.eval()
  correct=0
  total=0
  with torch.no_grad():
    for inputs,labels in data_loader:
      inputs, labels = inputs.to(device), labels.to(device)
      outputs=model(inputs)
      _,predicted= torch.max(outputs,1)
      total+= labels.size(0)
      correct += (predicted==labels).sum().item()
  return correct/total

def train (model,train_loader,optimizer,criterion):
  model.train()
  running_loss=0.0
  for inputs,labels in train_loader:
    inputs, labels = inputs.to(device), labels.to(device)
    optimizer.zero_grad()
    outputs=model(inputs)
    loss=criterion(outputs,labels)
    loss.backward()
    optimizer.step()
    running_loss += loss.item() * inputs.size(0)
  return running_loss/len(train_loader.dataset)

def validate (model,val_loader,criterion):
  model.eval()
  running_loss=0.0
  with torch.no_grad():
    for inputs,labels in val_loader:
      inputs, labels = inputs.to(device), labels.to(device)
      outputs=model(inputs)
      loss=criterion(outputs,labels)
      running_loss += loss.item() * inputs.size(0)
  return running_loss/len(val_loader.dataset)

train_losses=[]
val_losses=[]



for epoch in range(EPOCHS):
  train_loss=train(model,train_loader,optimizer,criterion)
  val_loss=validate(model,val_loader,criterion)
  train_accuarcy=compute_accuracy(model,train_loader)
  val_accuracy=compute_accuracy(model,val_loader)

  train_losses.append(train_loss)
  val_losses.append(val_loss)

  tqdm.write(f'Epoch{epoch+1}/{EPOCHS},'
             f'Train loss {train_loss:.4f},'
             f'Val loss {val_loss:.4f},'
             f'Train accuracy{train_accuarcy:.4f},'
             f'Val accuracy{val_accuracy:.4f}')


plt.plot(train_losses,label='Train loss')
plt.plot(val_losses,label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.title('Train and validation losses')
plt.legend()
plt.show()

def predict(model, test_loader):
    model.eval()
    predictions = []
    with torch.no_grad():
        for inputs, _ in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            predictions.extend(predicted.cpu().numpy())
    return predictions

test_predictions=predict(model,test_loader)
acc=accuracy_score(test_dataset.targets,test_predictions)
print(acc)

class_label_map = train_dataset.class_to_idx

for class_name, label in class_label_map.items():
    print(f"Class: {class_name}, and its label: {label}")

testing_dir='/content/test/beetroot/Image_6.jpg'

testing_photo=Image.open(testing_dir)

transfrom=torchvision.transforms.Compose([
    torchvision.transforms.Resize((227,227)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

input_tensor=transfrom(testing_photo).unsqueeze(0)

input_tensor=input_tensor.to(device)

model.eval()

with torch.no_grad():
  outputs=model(input_tensor)

_, predicted=torch.max(outputs,1)

predicted_class_name = list(class_label_map.keys())[list(class_label_map.values()).index(predicted.item())]

print(f"The predicted class label for the photo is: {predicted_class_name}")

